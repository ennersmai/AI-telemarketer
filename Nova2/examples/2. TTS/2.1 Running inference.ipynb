{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Running inference on a TTS (Text-to-Speech) model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TTS turns the LLMs response into speech, enabling interaction with the LLM without requiring a keyboard. This notebook will show you how to interact with the TTS system, as well as Novas audio player."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this code so python can find the scripts. This is not required when importing Nova from outside the root folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "module_path = Path().absolute().parent.parent\n",
    "if str(module_path) not in sys.path:\n",
    "    sys.path.append(str(module_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nova import *\n",
    "\n",
    "nova = Nova()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TTS system mirrors the LLM system in that you need to choose an inference engine, as well as prepare a \"conditioning\" object.  \n",
    "By default, Nova comes with 2 inference engines for the TTS system. One using [Zonos](https://github.com/Zyphra/Zonos) and one using [Elevenlabs](https://elevenlabs.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zonos:\n",
    "inference_engine = InferenceEngineZonos()\n",
    "\n",
    "# Elevenlabs:\n",
    "inference_engine = InferenceEngineElevenlabs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a TTSConditioning object. Just like with the LLM system, each inference engine varies in what parameters they need and they differ in what values should be used. Below is a set of starting values for both engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zonos conditioning:\n",
    "conditioning = TTSConditioning(\n",
    "    model=\"Zyphra/Zonos-v0.1-transformer\",\n",
    "    voice=\"Laura\",\n",
    "    expressivness=100,\n",
    "    stability=2.0,\n",
    "    language=\"en-us\",\n",
    "    speaking_rate=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:  \n",
    "- model: Which model to use. You can find the available models [here](https://huggingface.co/collections/Zyphra/zonos-v01-67ac661c85e1898670823b4f)\n",
    "- voice: The name of the voice to use. By default, Nova comes with 1 default voice \"Laura\", but you can clone other voices and use them. More on voice cloning in [2.2](2.2%20Cloning%20a%20voice.ipynb).\n",
    "- expressivness: How expressive the voice should sound. Higher means the voice speaks with more emotion anc variation but also loses stability.\n",
    "- stability: How stable the voice should be.\n",
    "- language: The language the voice should speak. Should be the same language the input text is in.\n",
    "- speaking_rate: How fast the voice should speak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elevenlabs conditioning:\n",
    "conditioning = TTSConditioning(\n",
    "    model=\"eleven_multilingual_v2\",\n",
    "    voice=\"Xb7hH8MSUJpSbSDYk0k2\",\n",
    "    expressivness=0.5,\n",
    "    stability=0.5,\n",
    "    similarity_boost=0.75,\n",
    "    use_speaker_boost=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:  \n",
    "- model: Which model to use. You can find all available models on the Elevenlabs [website](https://elevenlabs.io/app/home)\n",
    "- voice: The voice ID of your desired voice. The voice IDs can also be found on the Elevenlabs [website](https://elevenlabs.io/app/home)\n",
    "- expressivness: How expressive the voice should sound. Higher means the voice speaks with more emotion anc variation but also loses stability.\n",
    "- stability: How stable the voice should be.\n",
    "- similarity_boost: How consistent the voice should be. High values can cause artifacts.\n",
    "- use_speaker_boost: An additional boost to voice consistency at the cost of generation latency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using Elevenlabs, you also need to pass your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nova.edit_secret(Secrets.ELEVENLABS_API, \"YOUR-API-KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up the TTS system, similar to how the LLM system is set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nova.configure_tts(inference_engine=inference_engine, conditioning=conditioning)\n",
    "\n",
    "# You need to apply your new configuration.\n",
    "# Only after applying the configuration will the model be loaded into memory.\n",
    "nova.apply_config_tts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = nova.run_tts(\"We choose to go to the Moon, not because its easy, but because it is hard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have an \"AudioData\" object that can be parsed to the built in audio player to be played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nova.play_audio(audio_data=speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then wait until the audio has finished playing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nova.wait_for_audio_playback_end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
